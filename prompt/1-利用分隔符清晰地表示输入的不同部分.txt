
把用三个反引号括起来的文本总结成一句话。

```
在图像生成领域，以 Stable Diffusion 为代表的扩散模型已然成为当前占据主导地位的范式。但扩散模型依赖于迭代推理，这是一把双刃剑，因为迭代方法可以实现具有简单目标的稳定训练，但推理过程需要高昂的计算成本。

在 Stable Diffusion 之前，生成对抗网络（GAN）是图像生成模型中常用的基础架构。相比于扩散模型，GAN 通过单个前向传递生成图像，因此本质上是更高效的。但由于训练过程的不稳定性，扩展 GAN 需要仔细调整网络架构和训练因素。因此，GAN 方法很难扩展到非常复杂的数据集上，在实际应用方面，扩散模型比 GAN 方法更易于控制，这是 GAN 式微的原因之一。

当前，GAN 主要是通过手动注释训练数据或先验 3D 模型来保证其可控性，这通常缺乏灵活性、精确性和通用性。然而，一些研究者看重 GAN 在图像生成上的高效性，做出了许多改进 GAN 的尝试。

最近，来自马克斯・普朗克计算机科学研究所、MIT CSAIL 和谷歌的研究者们研究了一种控制 GAN 的新方法 DragGAN，能够让用户以交互的方式「拖动」图像的任何点精确到达目标点。
```